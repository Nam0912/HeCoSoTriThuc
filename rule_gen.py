import nltk
from nltk.corpus import wordnet as wn

# Táº£i dá»¯ liá»‡u WordNet náº¿u chÆ°a cÃ³
try:
    nltk.data.find('corpora/wordnet')
except LookupError:
    nltk.download('wordnet')


def clean_term(term):
    """Chuáº©n hÃ³a tá»«: chá»¯ thÆ°á»ng, thay dáº¥u _ báº±ng khoáº£ng tráº¯ng"""
    return term.lemmas()[0].name().lower().replace('_', ' ')


def generate_combined_knowledge_base(root_topics, filename="full_knowledge_base.txt"):
    """
    Sinh táº­p luáº­t tá»•ng há»£p cho ToanHoc.py:
    1. Luáº­t AND (&): Dá»±a trÃªn Cáº¥u táº¡o (Meronyms) - Náº¿u cÃ³ Ä‘á»§ bá»™ pháº­n -> Suy ra váº­t.
    2. Luáº­t OR (v): Dá»±a trÃªn PhÃ¢n loáº¡i (Hyponyms) - Náº¿u lÃ  loáº¡i con A hoáº·c B -> Suy ra cha.
    """
    rules = set()  # DÃ¹ng set Ä‘á»ƒ tá»± Ä‘á»™ng loáº¡i bá» luáº­t trÃ¹ng láº·p hoÃ n toÃ n
    seen_logic = set()  # Kiá»ƒm soÃ¡t logic Ä‘á»ƒ trÃ¡nh chá»“ng chÃ©o

    print(f"ğŸš€ Äang khá»Ÿi táº¡o tri thá»©c cho cÃ¡c chá»§ Ä‘á»: {root_topics}...")

    # Duyá»‡t qua tá»«ng chá»§ Ä‘á» gá»‘c vÃ  má»Ÿ rá»™ng xuá»‘ng cÃ¡c lá»›p con
    for topic in root_topics:
        synsets = wn.synsets(topic)
        if not synsets: continue

        # Sá»­ dá»¥ng hÃ ng Ä‘á»£i Ä‘á»ƒ duyá»‡t cÃ¢y (BFS)
        queue = [synsets[0]]
        processed_synsets = set()

        while queue:
            current_syn = queue.pop(0)

            # TrÃ¡nh vÃ²ng láº·p vÃ´ táº­n
            if current_syn.name() in processed_synsets:
                continue
            processed_synsets.add(current_syn.name())

            current_name = clean_term(current_syn)

            # ==========================================
            # 1. SINH LUáº¬T AND (&) - Cáº¤U Táº O (Parts -> Whole)
            # Logic: part1 & part2 -> whole
            # ==========================================
            parts = current_syn.part_meronyms()
            part_names = [clean_term(p) for p in parts if clean_term(p) != current_name]

            # Chá»‰ táº¡o luáº­t AND náº¿u cÃ³ Ã­t nháº¥t 2 bá»™ pháº­n (Ä‘á»ƒ logic cháº·t cháº½)
            if len(part_names) >= 2:
                # Láº¥y tá»‘i Ä‘a 3 bá»™ pháº­n Ä‘áº·c trÆ°ng nháº¥t Ä‘á»ƒ luáº­t khÃ´ng quÃ¡ dÃ i
                selected_parts = part_names[:3]
                premises = " & ".join(selected_parts)

                rule_str = f"{premises} -> {current_name} | Rule_CauTao_{current_name.replace(' ', '_')}"

                # Kiá»ƒm tra trÃ¹ng láº·p logic
                if rule_str not in rules:
                    rules.add(rule_str)

            # ==========================================
            # 2. SINH LUáº¬T OR (v) - PHÃ‚N LOáº I (Children -> Parent)
            # Logic: child1 v child2 -> parent
            # ==========================================
            hyponyms = current_syn.hyponyms()
            child_names = [clean_term(c) for c in hyponyms if clean_term(c) != current_name]

            # Gom nhÃ³m con: chia thÃ nh cÃ¡c nhÃ³m nhá» (chunk) Ä‘á»ƒ táº¡o luáº­t OR
            # VÃ­ dá»¥: xe sedan v xe táº£i -> xe hÆ¡i
            chunk_size = 4
            for i in range(0, len(child_names), chunk_size):
                chunk = child_names[i:i + chunk_size]
                if len(chunk) > 0:
                    if len(chunk) > 1:
                        # Táº¡o luáº­t OR
                        premises = " v ".join(chunk)
                        label = f"Rule_PhanLoai_OR_{current_name.replace(' ', '_')}_{i}"
                    else:
                        # Náº¿u chá»‰ cÃ³ 1 con láº» loi, táº¡o luáº­t Ä‘Æ¡n (Simple Rule)
                        premises = chunk[0]
                        label = f"Rule_PhanLoai_IsA_{current_name.replace(' ', '_')}_{i}"

                    rule_str = f"{premises} -> {current_name} | {label}"
                    rules.add(rule_str)

            # Tiáº¿p tá»¥c duyá»‡t sÃ¢u xuá»‘ng cÃ¡c con Ä‘á»ƒ má»Ÿ rá»™ng tri thá»©c
            # Giá»›i háº¡n Ä‘á»™ sÃ¢u báº±ng cÃ¡ch chá»‰ thÃªm vÃ o queue náº¿u chÆ°a duyá»‡t
            # (á» Ä‘Ã¢y duyá»‡t sÃ¢u tá»± nhiÃªn theo dá»¯ liá»‡u WordNet)
            for child in hyponyms:
                if child.name() not in processed_synsets:
                    queue.append(child)

            # Giá»›i háº¡n sá»‘ lÆ°á»£ng synset xá»­ lÃ½ Ä‘á»ƒ trÃ¡nh file quÃ¡ lá»›n (Optional)
            if len(processed_synsets) > 200:  # Xá»­ lÃ½ khoáº£ng 200 khÃ¡i niá»‡m má»—i chá»§ Ä‘á»
                break

    # ==========================================
    # GHI RA FILE
    # ==========================================
    with open(filename, "w", encoding="utf-8") as f:
        f.write("# Knowledge Base Generated from WordNet\n")
        f.write("# Format: Premises -> Conclusion | Label\n")
        f.write("# Contains both AND (&) and OR (v) rules.\n\n")

        # Sáº¯p xáº¿p Ä‘á»ƒ dá»… nhÃ¬n
        for r in sorted(list(rules)):
            f.write(r + "\n")

    print(f"âœ… ÄÃ£ hoÃ n táº¥t! File '{filename}' Ä‘Ã£ Ä‘Æ°á»£c táº¡o vá»›i {len(rules)} luáº­t.")
    print("ğŸ‘‰ HÃ£y náº¡p file nÃ y vÃ o ToanHoc.py vÃ  thá»­ nghiá»‡m.")


# --- Cáº¤U HÃŒNH CHáº Y ---
# Nháº­p cÃ¡c chá»§ Ä‘á» báº¡n muá»‘n táº¡o tri thá»©c
my_topics = ["car", "table"]
generate_combined_knowledge_base(my_topics)